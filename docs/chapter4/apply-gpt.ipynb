{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d784ea0",
   "metadata": {},
   "source": [
    "# 完整代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b38e1991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time,  I was a little bit of a fan of the original series, but I was also a little bit of a fan of the original series. I was a little bit of a fan of the original series, but I was also a little bit of a fan of the original series. I was a little bit of a fan of the original series, but I was also a little bit of a fan of the original series. I was a little bit of a fan of the original series, but I\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# 显式设置 pad_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "input_text = \"Once upon a time, \"\n",
    "inputs = tokenizer(input_text, return_tensors='pt')\n",
    "\n",
    "# 生成文本\n",
    "output = model.generate(**inputs, max_new_tokens=100, pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "# 解码输出\n",
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(decoded_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752cc67",
   "metadata": {},
   "source": [
    "# 逐句讲解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e34d8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b1ae5",
   "metadata": {},
   "source": [
    "这行代码从transformers库中导入GPT2LMHeadModel和GPT2Tokenizer类。\n",
    "\n",
    "GPT2LMHeadModel是GPT-2模型，它包括了语言模型头（用于文本生成）\n",
    "\n",
    "而GPT2Tokenizer是用于将文本转换为模型可以理解的数字表示（tokens）的类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d6c7830",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d428bcfa",
   "metadata": {},
   "source": [
    "这行代码创建了一个GPT2Tokenizer实例，并使用预训练的gpt2模型词汇表对其进行初始化。\n",
    "\n",
    "这意味着tokenizer对象已经知道如何将文本转换为模型可以理解的tokens。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fe0f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1124959",
   "metadata": {},
   "source": [
    "这行代码创建了一个GPT2LMHeadModel实例，并加载了预训练的gpt2模型权重。\n",
    "\n",
    "这样，model对象已经准备好了用于文本生成的预训练参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b5fcd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显式设置 pad_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589bea4f",
   "metadata": {},
   "source": [
    "这行代码将tokenizer的pad_token属性设置为eos_token的值。\n",
    "\n",
    "由于GPT-2模型没有定义pad_token，我们可以将其设置为eos_token，即序列结束的token。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838c200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Once upon a time, \"   # 要生成的文本的起始部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "842f98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(input_text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee4e62",
   "metadata": {},
   "source": [
    "这行代码使用tokenizer将input_text转换为模型可以理解的tokens，并返回一个字典，其中包含PyTorch张量（由return_tensors='pt'指定）。这些张量可以输入到模型中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5ce0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成文本\n",
    "output = model.generate(**inputs, max_new_tokens=100, pad_token_id=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b01aa9",
   "metadata": {},
   "source": [
    "这行代码调用模型的generate方法来生成文本。\n",
    "\n",
    "**inputs 是将inputs字典解包作为关键字参数传递给generate方法。\n",
    "\n",
    "max_new_tokens=100指定了模型应该生成的最大token数量。\n",
    "\n",
    "pad_token_id=tokenizer.pad_token_id传递了pad_token_id，尽管在生成文本时通常不需要它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ff7040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time,  I was a little bit of a fan of the original series, but I was also a little bit of a fan of the original series. I was a little bit of a fan of the original series, but I was also a little bit of a fan of the original series. I was a little bit of a fan of the original series, but I was also a little bit of a fan of the original series. I was a little bit of a fan of the original series, but I\n"
     ]
    }
   ],
   "source": [
    "# 解码输出\n",
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62686c7c",
   "metadata": {},
   "source": [
    "这行代码使用tokenizer的decode方法将模型生成的tokens转换为字符串。\n",
    "\n",
    "output[0]是生成的tokens的第一个元素（因为generate方法返回一个包含多个序列的列表，但这里只有一个序列）。\n",
    "\n",
    "skip_special_tokens=True告诉decode方法在转换过程中忽略特殊的tokens，如[PAD]、[EOS]等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757007b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
